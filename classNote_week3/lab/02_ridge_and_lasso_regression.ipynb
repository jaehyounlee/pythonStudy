{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보충 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_linear_regression.ipynb의 주요 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('data/bikeshare.csv')\n",
    "\n",
    "# Year와 Month를 추출\n",
    "datetime = pd.DatetimeIndex(data['datetime'])\n",
    "data['year'] = datetime.year\n",
    "data['month'] = datetime.month\n",
    "data['hour'] = datetime.hour\n",
    "\n",
    "# \"count\" is a method, so it's best to name that column something else\n",
    "data.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Handling 'season' variable\n",
    "season_dummies = pd.get_dummies(data.season, prefix='season')\n",
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, season_dummies], axis=1)\n",
    "\n",
    "# Add derivative variable \"daytime\"\n",
    "data['daytime'] = ((data.hour > 6) & (data.hour < 21)).astype(int)\n",
    "\n",
    "# Handling 'hour' variable\n",
    "hour_dummies = pd.get_dummies(data.hour, prefix='hour')\n",
    "hour_dummies.drop(hour_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, hour_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델을 학습하는 함수를 조금 수정하였습니다.\n",
    "다음을 포함하는 dictionary를 출력하는 함수로 변경하였습니다.\n",
    "- 각 변수에 대응하는 계수들(coefficients)과 intercept\n",
    "- Train set에서의 RMSE, R^2\n",
    "- Test set에서의 RMSE, R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a list of features and\n",
    "# returns coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "def train_test_linreg(d, feature_cols):\n",
    "    X = d[feature_cols]\n",
    "    Y = d.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = feature_cols)\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hour에 대한 binary dummy variable만 이용하여 선형회귀모델을 학습\n",
    "hour_cols = list(data.columns[data.columns.str.startswith('hour_')])\n",
    "result = train_test_linreg(data, hour_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression & Lasso regression\n",
    "### 두 모델의 공통점\n",
    "- **Regularization**: 모델 계수가 커지는 것에 대한 penalty를 부여함으로써 모델의 overfitting(과적합)을 방지\n",
    "- 기본적인 multiple linear regression (다중선형회귀분석) 은 변수 간의 [다중공산성(multicollinearity)](https://ko.wikipedia.org/wiki/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1)에 의해 성능이 하락하는데, 이 두 회귀모델은 이에 대해 대처할 수 있는 모델\n",
    "- 모델의 parameter(모수)가 존재: 계수 크기에 대한 penalty를 얼마나 줄 것인가 (**alpha**)\n",
    "- alpha가 0이면 단순 다중선형회귀모델과 일치하며, 일반적으로 0과 1사이의 값을 부여합니다. \n",
    "\n",
    "\n",
    "### Lasso regression의 강점\n",
    "- Lasso regression은 ridge regression과는 달리 특정 변수의 계수를 0으로 만들어줍니다. 특정 변수의 계수가 0이 아니라는 것은 **lasso regression 모델이 그 변수를 선택**했다고 볼 수 있습니다.\n",
    "- Lasso regression은 모든 변수가 선택되는 것이 아니라는 점에서 **sparse model** (희소모델)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 모델을 적용하기에 앞서 다음과 같은 데이터 전처리를 다시 실시하였습니다.\n",
    "- X에서 가능한 모든 변수를 사용하여, 모델의 성능이 어떻게 나오는지 파악\n",
    "- 제거한 변수: datetime (수치형 변수가 아니며, year/month/hour로 이미 분리됨),casual & registered (타겟변수인 'total'과 함께 움직이는 변수), total (타겟 변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_ridge(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Ridge(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_ridge(data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_lasso(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Lasso(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_lasso(data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파악할 부분\n",
    "- Ridge regression과 Lasso regression의 결과와 단순선형회귀모델의 결과를 비교해보세요.\n",
    "- 위의 Ridge regression과 Lasso regression에서 alpha값을 변형해가면서 결과가 달라지는지 살펴보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
