{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Pandas documentation: http://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "Pandas is well suited for many different kinds of data:\n",
    "- Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
    "- Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
    "- Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
    "- Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
    "\n",
    "Pandas만의 특이한 data structure\n",
    "- **Series** (1-dimensional)\n",
    "- **DataFrame** (2-dimensiona): R의 data frame과 거의 흡사하며 이를 다루는 함수 또한 R과 매우 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series\n",
    "- 1차원 배열\n",
    "- 자동으로 성분들이 0부터 시작하는 정수로 인덱싱됨. 이는 list와 tuple과 유사함\n",
    "- 인덱스를 자신이 원하는 형태로 바꿀 수 있다는 점에서 dictionary와 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.Series([1,2,3,4,5])\n",
    "print(a)\n",
    "# 1열은 index, 2열은 Series의 성분이 출력됨\n",
    "\n",
    "b = pd.Series([1,3,5,np.nan,6,8]) # NaN: Not a Number\n",
    "print(b)\n",
    "# Series에는 type이 다른 성분을 넣을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.Series([10000, 20000, 30000, 40000, 50000])\n",
    "print(a)\n",
    "print(a[0])\n",
    "print(a[2])\n",
    "\n",
    "# Series의 인덱싱을 날짜로 변경\n",
    "dates = pd.date_range('20160801', periods = 5)\n",
    "a = pd.Series([10000, 20000, 30000, 40000, 50000], index = dates)\n",
    "print(a)\n",
    "print(a['2016-08-01'])\n",
    "print(a['2016-08-03'])\n",
    "print(a[0])\n",
    "print(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WikiDocs [파이썬을 이용한 시스템 트레이딩(기초편)] 에서 가져온 예제\n",
    "mine = pd.Series([10,20,30], index=['naver','skt','kt'])\n",
    "wife = pd.Series([10,30,20], index=['kt','naver','skt'])\n",
    "\n",
    "family = mine + wife\n",
    "print(family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DataFrame\n",
    "- 2차원 형태의 자료구조\n",
    "- R의 dataframe과 거의 유사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WikiDocs [파이썬을 이용한 시스템 트레이딩(기초편)] 에서 가져온 예제\n",
    "raw_data = {'col0': [1,2,3,4],\n",
    "           'col1': [10,20,30,40],\n",
    "           'col2': [100,200,300,400]}\n",
    "data = pd.DataFrame(raw_data)\n",
    "print(data)\n",
    "print(data['col1'])\n",
    "\n",
    "print(type(raw_data)) # 위에서 정의한 raw_data는 dictionary임을 확인\n",
    "print(type(data)) # DataFrame이라는 type임을 확인\n",
    "print(type(data['col1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'A' : 1., \n",
    "                    'B' : pd.Timestamp('20130102'),\n",
    "                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                    'D' : np.array([3] * 4,dtype='int32'),\n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                    'F' : 'foo' })\n",
    "\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "print(df.head(2))\n",
    "print(df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index = dates, columns=list('ABCD'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'temperature': [29, 34, 36, 32, 30],\n",
    "       'humidity': ['mid', 'high', 'high', 'mid', 'low'],\n",
    "       'weather': ['cloudy', 'sunny', 'rainy', 'cloudy', 'sunny']}\n",
    "a = pd.DataFrame(data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index에 날짜를 넣기\n",
    "date = ['2016-08-01', '2016-08-02', '2016-08-03', '2016-08-04', '2016-08-05']\n",
    "# 변수의 순서를 정해주기\n",
    "features = ['temperature', 'humidity', 'weather']\n",
    "b = pd.DataFrame(data, columns = features, index = date)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame에서 특정 열을 가져오는 방법 1\n",
    "b.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame에서 특정 열을 가져오는 방법 2\n",
    "b['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 특정 인덱스의 행을 가져오는 방법\n",
    "b.ix['2016-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame에 'windy'라는 새로운 열을 추가\n",
    "windy = ['yes', 'no', 'yes', 'yes', 'no']\n",
    "b['windy'] = windy\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temperature가 30도 이하이고, weather가 sunny이면\n",
    "# 나가서 논다는 데이터를 입력해봅시다.\n",
    "b['play'] = (b['temperature'] <= 30) & (b['weather'] == 'sunny')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given the DataFrame\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose the DataFrame\n",
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete the column 'humidity'\n",
    "del b['humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data join\n",
    "There are actually four types of joins supported by the Pandas `merge` function. Here's how they are described by the documentation:\n",
    "\n",
    "- **inner:** use intersection of keys from both frames (SQL: inner join)\n",
    "- **outer:** use union of keys from both frames (SQL: full outer join)\n",
    "- **left:** use only keys from left frame (SQL: left outer join)\n",
    "- **right:** use only keys from right frame (SQL: right outer join)\n",
    "\n",
    "The default is the \"inner join\", which was used when creating the movie_ratings DataFrame.\n",
    "\n",
    "It's easiest to understand the different types by looking at some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = pd.DataFrame({'color': ['green', 'yellow', 'red'], 'num':[1, 2, 3]})\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = pd.DataFrame({'color': ['green', 'yellow', 'pink'], 'size':['S', 'M', 'L']})\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner join\n",
    "A와 B에 동시에 등장하는 포인트들을 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer join\n",
    "A 또는 B에 모두 등장하는 포인트들을 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left join\n",
    "A에 포함된 포인트들만 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right join\n",
    "B에 포함된 포인트들만 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "(From Kevin Markham's data science course)\n",
    "\n",
    "Using the [MovieLens 100k data](http://grouplens.org/datasets/movielens/), let's create two DataFrames:\n",
    "\n",
    "- **movies**: shows information about movies, namely a unique **movie_id** and its **title**\n",
    "- **ratings**: shows the **rating** that a particular **user_id** gave to a particular **movie_id** at a particular **timestamp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.item'\n",
    "movie_cols = ['movie_id', 'title']\n",
    "movies = pd.read_table(movie_url, sep='|', header=None, names=movie_cols, usecols=[0, 1])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rating_url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.data'\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table(rating_url, sep='\\t', header=None, names=rating_cols)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend that you want to examine the ratings DataFrame, but you want to know the **title** of each movie rather than its **movie_id**. The best way to accomplish this objective is by \"joining\" (or \"merging\") the DataFrames using the Pandas `merge` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_ratings = pd.merge(movies, ratings)\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what just happened:\n",
    "\n",
    "- Pandas noticed that movies and ratings had one column in common, namely **movie_id**. This is the \"key\" on which the DataFrames will be joined.\n",
    "- The first **movie_id** in movies is 1. Thus, Pandas looked through every row in the ratings DataFrame, searching for a movie_id of 1. Every time it found such a row, it recorded the **user_id**, **rating**, and **timestamp** listed in that row. In this case, it found 452 matching rows.\n",
    "- The second **movie_id** in movies is 2. Again, Pandas did a search of ratings and found 131 matching rows.\n",
    "- This process was repeated for all of the remaining rows in movies.\n",
    "\n",
    "At the end of the process, the movie_ratings DataFrame is created, which contains the two columns from movies (**movie_id** and **title**) and the three other colums from ratings (**user_id**, **rating**, and **timestamp**).\n",
    "\n",
    "- **movie_id** 1 and its **title** are listed 452 times, next to the **user_id**, **rating**, and **timestamp** for each of the 452 matching ratings.\n",
    "- **movie_id** 2 and its **title** are listed 131 times, next to the **user_id**, **rating**, and **timestamp** for each of the 131 matching ratings.\n",
    "- And so on, for every movie in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "print(ratings.shape)\n",
    "print(movie_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the shapes of the three DataFrames:\n",
    "\n",
    "- There are 1682 rows in the movies DataFrame.\n",
    "- There are 100000 rows in the ratings DataFrame.\n",
    "- The `merge` function resulted in a movie_ratings DataFrame with 100000 rows, because every row from ratings matched a row from movies.\n",
    "- The movie_ratings DataFrame has 5 columns, namely the 2 columns from movies, plus the 4 columns from ratings, minus the 1 column in common.\n",
    "\n",
    "By default, the `merge` function joins the DataFrames using all column names that are in common (**movie_id**, in this case). The [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) explains how you can override this behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
