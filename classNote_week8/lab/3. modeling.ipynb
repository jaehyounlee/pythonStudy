{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 내용\n",
    "\n",
    "1. 데이터 수집\n",
    "2. 데이터 전처리, 탐색, 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그럼 이제 데이터 분석을 할 차례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (Supervised) 후보를 설명하는 단어 추출\n",
    "\n",
    "    - 입력변수: 뉴스에 등장한 단어의 tf-idf 값\n",
    "    - 출력변수: 후보에 대한 뉴스 여부\n",
    "\n",
    "2. (Unsupervised) 대선 주요 토픽 탐색\n",
    "\n",
    "    - 입력데이터: 뉴스 데이터\n",
    "    - 출력변수: 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_list = ['문재인', '안철수', '유승민', '홍준표', '심상정']\n",
    "columns = ['sid', 'press', 'date', 'title', 'contents', 'label', 'len_news', 'num_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "seen_aid = set()\n",
    "\n",
    "for cand in cand_list:\n",
    "    dir_path = os.path.join('./data/', cand)\n",
    "    \n",
    "    for file_name in os.listdir(dir_path):\n",
    "        sid, _, aid = file_name.replace('.json', '').split('-')\n",
    "        \n",
    "        if aid in seen_aid:\n",
    "            try:\n",
    "                df.drop(aid, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            seen_aid.add(aid)\n",
    "\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        \n",
    "            # add columns\n",
    "            data['label'] = cand\n",
    "            data['sid'] = sid\n",
    "            data['date'] = data['datetime'][:10]\n",
    "            data['len_news'] = len(data['contents'])\n",
    "            data['num_sent'] = len(data['contents'].split('.'))\n",
    "            # modify columns\n",
    "            data['contents'] = data['contents'].replace('\\r', '').replace('\\n', '')\n",
    "            \n",
    "            for col in columns:\n",
    "                df.loc[aid, col] = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter some news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분석에 불필요한 뉴스를 제외하기\n",
    "\n",
    "1. 길이가 짧은 뉴스: 200자 이상만 남기기\n",
    "2. 포토 뉴스\n",
    "3. 속보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rows(df, word_list):\n",
    "    for word in word_list:\n",
    "        df = df[df.apply(lambda x: word not in x.title, axis=1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = filter_rows(df, ['포토', '사진', '속보'])\n",
    "df_filtered = df_filtered[df_filtered.len_news > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extarct Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "news_noun_list = [\n",
    "    twitter.nouns(news) for news in df_filtered['contents']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_list = set('문재인 안철수 심상정 홍준표 유승민 민주당 국민의당 정의당 바른정당 자유한국당 기자 무단 정당 대표 후보 대선 경선 의원 대통령 기사 정치 선거'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "all_nouns = tuple(chain(*news_noun_list))\n",
    "\n",
    "# feature가 될 단어의 조건\n",
    "# 1. 등장 횟수가 6회 이상\n",
    "# 2. 단어 길이 2 이상\n",
    "# 3. 사전에 등록된 불용어(stopword)가 아님\n",
    "feature_list = [\n",
    "    word for word, count in Counter(all_nouns).items()\n",
    "    if count > 5 and len(word) > 1 and word not in stop_list\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# 뉴스별로 단어의 등장여부 딕셔너리 만들기\n",
    "news_count_list = [Counter(news_noun) for news_noun in news_noun_list]\n",
    "# feature_list에 등장하는 feature 단어 순으로 등장 횟수 list 만들기\n",
    "tf = [[count[f] for f in feature_list] for count in news_count_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np array, 즉, term frequency matrix로 바꾸기\n",
    "tf = np.array(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf-idf matrix로 바꾸기\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "type(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term frequency matrix는 sparse한, 즉 대부분 성분값이 0인 행렬이다. 따라서 메모리 효율을 위해 sparse matrix 자료구조를 사용한다. 우리가 알고 있는 numpy array 형태로 바꾸자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.toarray()\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y(cand):\n",
    "    return np.array([1 if label==cand else 0 for label in df_filtered['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printf_list(num_feature, feature_score, feature_name):\n",
    "    top_k_indices = np.argsort(-feature_score)[:num_feature]\n",
    "    for i, k in enumerate(top_k_indices):\n",
    "        print('{}'.format(feature_name[k]), end=', ')\n",
    "        if (i+1)%10 == 0:\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for cand in cand_list:\n",
    "    print('--------{}--------'.format(cand))\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X, get_y(cand)) # clf.feature_importances_\n",
    "    printf_list(30, clf.feature_importances_, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for cand in cand_list:\n",
    "    print('--------{}--------'.format(cand))\n",
    "    clf = LogisticRegression(penalty='l1', C=1)\n",
    "    y_true = get_y(cand)\n",
    "    clf.fit(X, y_true) # clf.coef_\n",
    "    y_pred = clf.predict(X)\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print(np.sum(clf.coef_[0] != 0))\n",
    "    printf_list(20, clf.coef_[0], feature_list)\n",
    "    print('-')\n",
    "    printf_list(20, -clf.coef_[0], feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문재인 vs 안철수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered['label'] != '안철수' \n",
    "\n",
    "case = {\n",
    "    '문재인': 1,\n",
    "    '홍준표': 0,\n",
    "}\n",
    "\n",
    "case_value = np.array(\n",
    "    [case[label] if label in case else -1 for label in df_filtered['label']]\n",
    ")\n",
    "\n",
    "indices = np.argwhere(case_value != -1)\n",
    "y_true = case_value[indices].reshape(-1)\n",
    "X_filtered = X[indices].reshape(y_true.shape[0], X.shape[1])\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', C=1)\n",
    "clf.fit(X_filtered, y_true) # clf.coef_\n",
    "y_pred = clf.predict(X_filtered)\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(np.sum(clf.coef_[0] != 0))\n",
    "print('--- 문재인 관련 키워드: ')\n",
    "printf_list(20, clf.coef_[0], feature_list)\n",
    "print('--- 홍준표 관련 키워드: ')\n",
    "printf_list(20, -clf.coef_[0], feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_set = set(feature_list)\n",
    "doc_list = [\n",
    "    [noun for noun in news if noun in feature_set] for news in news_noun_list\n",
    "] # news 별로 feature_set에 들어가는 단어만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.dictionary.Dictionary(doc_list)\n",
    "# dictionary 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(nouns) for nouns in doc_list]\n",
    "# document를 bag-of-words 벡터로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus, \n",
    "    id2word=dictionary, \n",
    "    num_topics=100\n",
    ") # lda modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis.gensim import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
