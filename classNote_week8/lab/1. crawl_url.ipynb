{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 온라인 뉴스 데이터 수집\n",
    "\n",
    "웹사이트의 데이터가 언제나 CSV나 JSON과 같은 편안한 형식으로 제공되지 않는다.\n",
    "\n",
    "그러나, HTML 데이터는 구조화된 데이터이므로, 웹 스크래핑을 통해 데이터를 수집할 수 있다.\n",
    "\n",
    "### 웹 스크래핑\n",
    "- 컴퓨터 프로그램을 통해 웹 페이지를 탐색하고 필요한 데이터를 유용한 형식에 맞춰 수집하는 작업\n",
    "- 크롤링이라고도 부름\n",
    "- 웹 스크래핑을 명시적으로 금지하는 경우도 많으며, API를 통해서만 데이터를 제공하는 경우도 많다\n",
    "    - 사이트의 이용약관을 확인하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 데이터 수집\n",
    "\n",
    "- http://news.naver.com/\n",
    "- http://news.naver.com/main/search/search.nhn?\n",
    "- 사이트 구조와 html 구조를 이해하면 쉽게 가져올 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import requests\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(qword, sdate, edate, page):\n",
    "    \"\"\"\n",
    "    description: 뉴스 검색 결과 url을 가져오는 함수\n",
    "    \n",
    "    input: 검색 키워드 문자열\n",
    "           뉴스 기간 시작일과 종료일\n",
    "           검색 결과의 페이지 번호\n",
    "    output: 검색 결과 url\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = (\n",
    "        'http://news.naver.com/main/search/search.nhn?'\n",
    "        'query={}&startDate={}&endDate={}&page={}'\n",
    "    )\n",
    "    # '문재인' --> '%B9%AE%C0%E7%C0%CE'\n",
    "    qword = quote(qword, encoding='MS949') #EUC-KR OK\n",
    "    return_url = base_url.format(qword, sdate, edate, page)\n",
    "    return return_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = get_url(\"문재인\", '2017-07-14', '2017-07-14', 1)\n",
    "my_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    \"\"\"\n",
    "    description: url에 해당하는 html 문자열을 가져옴\n",
    "    \n",
    "    input: url\n",
    "    output: html 문자열    \n",
    "    \"\"\"\n",
    "    page_html = requests.get(url).text\n",
    "    return page_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_html = get_html(my_url)\n",
    "my_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_go_naver_urls(page_html):\n",
    "    # beautifulsoup documentation: \n",
    "    # https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "    soup = bsoup(page_html, 'html.parser')\n",
    "    href_list = soup.find_all('a', class_='go_naver')\n",
    "    href_list = [href.get('href') for href in href_list]\n",
    "    return href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_urls = get_go_naver_urls(my_html)\n",
    "my_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_news(url):\n",
    "    \"\"\"\n",
    "    description: 네이버 뉴스 기사 url을 받아서, 필요한 내용만 추출하여 딕셔너리로 반환\n",
    "    \n",
    "    input: 네이버 뉴스 기사 url\n",
    "    output: {뉴스기사 제목, 내용, 언론사, 일시}로 구성된 딕셔너리\n",
    "    \"\"\"\n",
    "    page_html = get_html(url)\n",
    "    soup = bsoup(page_html, 'html.parser')\n",
    "    title = soup.find('h3', id='articleTitle')\n",
    "    if title:\n",
    "        title = title.text\n",
    "        press = soup.find('div', class_=\"press_logo\")\n",
    "        press = press.img.get('title')\n",
    "        dt = soup.find('span', class_='t11').text\n",
    "        article = soup.find('div', id='articleBodyContents').text\n",
    "        news_dic = {\n",
    "            'title': title,\n",
    "            'press': press,\n",
    "            'datetime': dt,\n",
    "            'article': article\n",
    "        }\n",
    "        return news_dic\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in my_urls:\n",
    "    my_dict = get_news(url)\n",
    "    print(my_dict)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qword = '문재인' #%B9%AE%C0%E7%C0%CE\n",
    "sdate = '2017-07-14'\n",
    "edate = '2017-07-14'\n",
    "page = 1\n",
    "\n",
    "url = get_url(qword, sdate, edate, page)\n",
    "print(url)\n",
    "page_html = get_html(url)\n",
    "href_list = get_go_naver_urls(page_html)\n",
    "for href in href_list:\n",
    "    print(href)\n",
    "    news = get_news(href)\n",
    "    if news:\n",
    "        print(get_news(href))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
